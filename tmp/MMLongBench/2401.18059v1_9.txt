Published as a conference paper at ICLR 2024
6
REPRODUCIBILITY STATEMENT
Language Models for QA and Summarization
Four language models are used in our RAPTOR
experiments: GPT-3 and GPT-4 for QA tasks, and GPT-3.5-turbo for summarization. The gpt-3,
gpt-4, and gpt-3.5-turbo models can be accessed via API calls (OpenAI API). UnifiedQA,
which is used for QA tasks, is publicly available at Hugging Face.
Evaluation Datasets
The three evaluation datasets used in our experiments—QuALITY,
QASPER, and NarrativeQA—are all publicly accessible. These datasets ensure that the retrieval
and QA tests conducted in this study can be replicated.
Source Code
The source code for RAPTOR will be publicly available here.
REFERENCES
Charu C Aggarwal, Alexander Hinneburg, and Daniel A Keim. On the Surprising Behavior of Dis-
tance Metrics in High Dimensional Space. In Database Theory—ICDT 2001: 8th International
Conference London, UK, January 4–6, 2001 Proceedings 8, pp. 420–434. Springer, 2001. URL
https://link.springer.com/chapter/10.1007/3-540-44503-x_27.
Joshua Ainslie, Tao Lei, Michiel de Jong, Santiago Onta˜n´on, Siddhartha Brahma, Yury Zemlyan-
skiy, David Uthus, Mandy Guo, James Lee-Thorp, Yi Tay, et al.
CoLT5: Faster long-range
transformers with conditional computation.
arXiv preprint arXiv:2303.09752, 2023.
URL
https://arxiv.org/abs/2303.09752.
Ekin Akyurek, Tolga Bolukbasi, Frederick Liu, Binbin Xiong, Ian Tenney, Jacob Andreas, and
Kelvin Guu.
Towards tracing knowledge in language models back to the training data.
In
Findings of the Association for Computational Linguistics: EMNLP 2022, pp. 2429–2446,
Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics.
doi: 10.18653/v1/2022.findings-emnlp.180. URL https://aclanthology.org/2022.
findings-emnlp.180.
Stefanos Angelidis and Mirella Lapata. Summarizing opinions: Aspect extraction meets sentiment
prediction and they are both weakly supervised. arXiv preprint arXiv:1808.08858, 2018. URL
https://arxiv.org/abs/1808.08858.
Manoj Ghuhan Arivazhagan, Lan Liu, Peng Qi, Xinchi Chen, William Yang Wang, and Zhiheng
Huang.
Hybrid hierarchical retrieval for open-domain question answering.
In Anna Rogers,
Jordan Boyd-Graber, and Naoaki Okazaki (eds.), Findings of the Association for Computational
Linguistics: ACL 2023, pp. 10680–10689, Toronto, Canada, July 2023. Association for Computa-
tional Linguistics. doi: 10.18653/v1/2023.findings-acl.679. URL https://aclanthology.
org/2023.findings-acl.679.
Iz Beltagy, Matthew E. Peters, and Arman Cohan. Longformer: The Long-document Transformer,
2020. URL https://arxiv.org/abs/2004.05150. arXiv preprint arXiv:2004.05150.
Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Milli-
can, George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, et al.
Improving language models by retrieving from trillions of tokens. In International conference on
machine learning, pp. 2206–2240. PMLR, 2022. URL https://arxiv.org/abs/2112.
04426.
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhari-
wal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal,
Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel
Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin,
Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Rad-
ford, Ilya Sutskever, and Dario Amodei.
Language Models are Few-Shot Learners.
In
H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (eds.), Advances in Neu-
ral Information Processing Systems, volume 33, pp. 1877–1901. Curran Associates, Inc.,
10
